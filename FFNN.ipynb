{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvXNRg0BR1qB",
        "outputId": "435327b3-2730-4768-e894-6854ba809393"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2pijLT3SHFD"
      },
      "outputs": [],
      "source": [
        "glove_path = '/content/drive/MyDrive/glove.6B.100d.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcHfqmFWSNKO",
        "outputId": "5ef506bd-2f99-4f13-9225-20f27e9cb292"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting conllu\n",
            "  Downloading conllu-4.5.3-py2.py3-none-any.whl (16 kB)\n",
            "Installing collected packages: conllu\n",
            "Successfully installed conllu-4.5.3\n"
          ]
        }
      ],
      "source": [
        "!pip install conllu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cL3uEjpASPv-",
        "outputId": "df15bb02-d6f0-4d47-f772-4075b3772eba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.3.1-py3-none-any.whl (840 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.4/840.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.25.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.10.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.10.1 torchmetrics-1.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9COAqaarVMm"
      },
      "source": [
        "My FFNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7g48K_erSR0p",
        "outputId": "3979400f-0ccb-4397-8454-c4ee05a3ce76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dev Set Accuracy for config: {'hidden_size': 64, 'num_layers': 1, 'embedding_dim': 50, 'activation': ReLU()}, Accuracy: 0.9835942203491872\n",
            "Dev Set Accuracy for config: {'hidden_size': 128, 'num_layers': 2, 'embedding_dim': 100, 'activation': ReLU()}, Accuracy: 0.9825406381697772\n",
            "Dev Set Accuracy for config: {'hidden_size': 128, 'num_layers': 3, 'embedding_dim': 200, 'activation': Tanh()}, Accuracy: 0.9820891029500302\n",
            "Dev Set Accuracy for config: {'hidden_size': 256, 'num_layers': 4, 'embedding_dim': 200, 'activation': ReLU()}, Accuracy: 0.9817880794701986\n",
            "Best Hyperparameter Configuration: {'hidden_size': 64, 'num_layers': 1, 'embedding_dim': 50, 'activation': ReLU()}, Dev Set Accuracy: 0.9835942203491872\n",
            "Test Set Accuracy for Best Configuration: 0.9822188449848024\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "from conllu import parse_incr\n",
        "from collections import defaultdict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "START_TOKEN = '<START>'\n",
        "END_TOKEN = '<END>'\n",
        "\n",
        "\n",
        "train_input_sequences = [create_input_sequence_with_embeddings(sentence, glove_embeddings, CONTEXT_SIZE) for sentence in train_sentences]\n",
        "train_pos_indices = [pos_tag_to_idx[tag] for sentence in train_sentences for _, _, tag in sentence]\n",
        "train_input_sequences_flat = [embedding for sequence in train_input_sequences for embedding in sequence]\n",
        "train_input_tensors = torch.tensor(train_input_sequences_flat, dtype=torch.float32)\n",
        "train_label_tensors = torch.tensor(train_pos_indices, dtype=torch.long)\n",
        "\n",
        "dev_input_sequences = [create_input_sequence_with_embeddings(sentence, glove_embeddings, CONTEXT_SIZE) for sentence in dev_sentences]\n",
        "dev_pos_indices = [pos_tag_to_idx[tag] for sentence in dev_sentences for _, _, tag in sentence]\n",
        "\n",
        "test_input_sequences = [create_input_sequence_with_embeddings(sentence, glove_embeddings, CONTEXT_SIZE) for sentence in test_sentences]\n",
        "test_pos_indices = [pos_tag_to_idx[tag] for sentence in test_sentences for _, _, tag in sentence]\n",
        "\n",
        "dev_input_sequences_flat = [embedding for sequence in dev_input_sequences for embedding in sequence]\n",
        "dev_input_tensors = torch.tensor(dev_input_sequences_flat, dtype=torch.float32)\n",
        "dev_label_tensors = torch.tensor(dev_pos_indices, dtype=torch.long)\n",
        "\n",
        "test_input_sequences_flat = [embedding for sequence in test_input_sequences for embedding in sequence]\n",
        "test_input_tensors = torch.tensor(test_input_sequences_flat, dtype=torch.float32)\n",
        "test_label_tensors = torch.tensor(test_pos_indices, dtype=torch.long)\n",
        "\n",
        "# pos_idx_to_tag = {idx: tag for tag, idx in pos_tag_to_idx.items()}\n",
        "\n",
        "\n",
        "def read_conllu_file(file_path):\n",
        "    sentences = []\n",
        "    pos_tags = set()\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for tokenlist in parse_incr(f):\n",
        "            sentence = []\n",
        "            for token in tokenlist:\n",
        "                word_index = token[\"id\"]\n",
        "                lowercase_word = token[\"form\"].lower()\n",
        "                pos_tag = token[\"upos\"]\n",
        "                sentence.append((word_index, lowercase_word, pos_tag))\n",
        "                pos_tags.add(pos_tag)\n",
        "            sentences.append(sentence)\n",
        "    return sentences, pos_tags\n",
        "\n",
        "def load_glove_embeddings(file_path):\n",
        "    embeddings = {}\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.strip().split(' ')\n",
        "            word = values[0]\n",
        "            vector = np.array(values[1:], dtype=np.float32)\n",
        "            embeddings[word] = vector\n",
        "    return embeddings\n",
        "\n",
        "def create_input_sequence_with_embeddings(sentence, glove_embeddings, context_size):\n",
        "    START_TOKEN = '<START>'\n",
        "    END_TOKEN = '<END>'\n",
        "    sentence_with_tokens = [START_TOKEN] * context_size[0] + [token[1] for token in sentence] + [END_TOKEN] * context_size[1]\n",
        "    input_sequences = []\n",
        "    for i in range(context_size[0], len(sentence_with_tokens) - context_size[1]):\n",
        "        context_words = sentence_with_tokens[i - context_size[0]: i + context_size[1] + 1]\n",
        "        context_embeddings = [glove_embeddings[word] if word in glove_embeddings else np.zeros(EMBEDDING_DIM) for word in context_words]\n",
        "        input_sequence = np.concatenate(context_embeddings)\n",
        "        input_sequences.append(input_sequence)\n",
        "    return input_sequences\n",
        "\n",
        "def predict_pos_tags(sentence, model, glove_embeddings, context_size, pos_idx_to_tag):\n",
        "    START_TOKEN = '<START>'\n",
        "    END_TOKEN = '<END>'\n",
        "    tokens = nltk.word_tokenize(sentence)\n",
        "    sentence_with_tokens = [START_TOKEN] * context_size[0] + [token for token in tokens] + [END_TOKEN] * context_size[1]\n",
        "    input_sequences = []\n",
        "    for i in range(context_size[0], len(sentence_with_tokens) - context_size[1]):\n",
        "        context_words = sentence_with_tokens[i - context_size[0]: i + context_size[1] + 1]\n",
        "        context_embeddings = [glove_embeddings[word] if word in glove_embeddings else np.zeros(EMBEDDING_DIM) for word in context_words]\n",
        "        input_sequence = np.concatenate(context_embeddings)\n",
        "        input_sequences.append(input_sequence)\n",
        "    input_tensor = torch.tensor(input_sequences, dtype=torch.float32)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_tensor)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "    predicted_tags = [pos_idx_to_tag[idx.item()] for idx in predicted]\n",
        "    return predicted_tags\n",
        "\n",
        "train_file = \"en_atis-ud-train.conllu\"\n",
        "dev_file = \"en_atis-ud-dev.conllu\"\n",
        "test_file = \"en_atis-ud-test.conllu\"\n",
        "\n",
        "train_sentences, train_pos_tags = read_conllu_file(train_file)\n",
        "dev_sentences, dev_pos_tags = read_conllu_file(dev_file)\n",
        "test_sentences, test_pos_tags = read_conllu_file(test_file)\n",
        "\n",
        "all_pos_tags = train_pos_tags.union(dev_pos_tags).union(test_pos_tags)\n",
        "pos_tag_to_idx = {tag: idx for idx, tag in enumerate(sorted(all_pos_tags))}\n",
        "pos_idx_to_tag = {idx: tag for tag, idx in pos_tag_to_idx.items()}\n",
        "\n",
        "\n",
        "glove_embeddings = load_glove_embeddings(glove_path)\n",
        "\n",
        "class FFNN_POS_Tagging(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes, num_layers=1, activation=nn.ReLU()):\n",
        "        super(FFNN_POS_Tagging, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.hidden_layers = nn.ModuleList([nn.Linear(hidden_size, hidden_size) for _ in range(num_layers - 1)])\n",
        "        self.relu = activation\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        for layer in self.hidden_layers:\n",
        "            out = layer(out)\n",
        "            out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "hyperparameter_configs = [\n",
        "    {'hidden_size': 64, 'num_layers': 1, 'embedding_dim': 50, 'activation': nn.ReLU()},\n",
        "    {'hidden_size': 128, 'num_layers': 2, 'embedding_dim': 100, 'activation': nn.ReLU()},\n",
        "    {'hidden_size': 128, 'num_layers': 3, 'embedding_dim': 200, 'activation': nn.Tanh()},\n",
        "    {'hidden_size': 256, 'num_layers': 4, 'embedding_dim': 200, 'activation': nn.ReLU()}\n",
        "]\n",
        "\n",
        "train_input_tensors, val_input_tensors, train_label_tensors, val_label_tensors = train_test_split(train_input_tensors, train_label_tensors, test_size=0.1, random_state=42)\n",
        "\n",
        "best_dev_accuracy = 0.0\n",
        "best_config = None\n",
        "\n",
        "# CONTEXT_SIZE = (2, 3)  # p = 2, s = 3\n",
        "EMBEDDING_DIM = 100\n",
        "NUM_POS_TAGS = len(pos_tag_to_idx)\n",
        "\n",
        "for config in hyperparameter_configs:\n",
        "    model = FFNN_POS_Tagging(input_size= EMBEDDING_DIM * (sum(CONTEXT_SIZE)+1),\n",
        "                              hidden_size=config['hidden_size'],\n",
        "                              num_classes=NUM_POS_TAGS,\n",
        "                              num_layers=config['num_layers'],\n",
        "                              activation=config['activation'])\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    batch_size = 32\n",
        "    epochs = 10\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        num_batches = len(train_input_tensors) // batch_size\n",
        "        for i in range(num_batches):\n",
        "            batch_inputs = train_input_tensors[i * batch_size: (i + 1) * batch_size]\n",
        "            batch_labels = train_label_tensors[i * batch_size: (i + 1) * batch_size]\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_inputs)\n",
        "            loss = criterion(outputs, batch_labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        avg_loss = running_loss / num_batches\n",
        "\n",
        "    dev_correct = 0\n",
        "    dev_total = 0\n",
        "    with torch.no_grad():\n",
        "        dev_outputs = model(dev_input_tensors)\n",
        "        _, dev_predicted = torch.max(dev_outputs, 1)\n",
        "        dev_total += dev_label_tensors.size(0)\n",
        "        dev_correct += (dev_predicted == dev_label_tensors).sum().item()\n",
        "\n",
        "    dev_accuracy = dev_correct / dev_total\n",
        "    print(f'Dev Set Accuracy for config: {config}, Accuracy: {dev_accuracy}')\n",
        "\n",
        "    if dev_accuracy > best_dev_accuracy:\n",
        "        best_dev_accuracy = dev_accuracy\n",
        "        best_config = config\n",
        "\n",
        "print(f'Best Hyperparameter Configuration: {best_config}, Dev Set Accuracy: {best_dev_accuracy}')\n",
        "\n",
        "\n",
        "best_model = FFNN_POS_Tagging(input_size= EMBEDDING_DIM * (sum(CONTEXT_SIZE)+1),\n",
        "                               hidden_size=best_config['hidden_size'],\n",
        "                               num_classes=NUM_POS_TAGS,\n",
        "                               num_layers=best_config['num_layers'],\n",
        "                               activation=best_config['activation'])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(best_model.parameters(), lr=0.001)\n",
        "\n",
        "final_train_input = torch.cat([train_input_tensors, val_input_tensors], dim=0)\n",
        "final_train_labels = torch.cat([train_label_tensors, val_label_tensors], dim=0)\n",
        "\n",
        "batch_size = 32\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    num_batches = len(final_train_input) // batch_size\n",
        "    for i in range(num_batches):\n",
        "        batch_inputs = final_train_input[i * batch_size: (i + 1) * batch_size]\n",
        "        batch_labels = final_train_labels[i * batch_size: (i + 1) * batch_size]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = best_model(batch_inputs)\n",
        "        loss = criterion(outputs, batch_labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_loss = running_loss / num_batches\n",
        "\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "with torch.no_grad():\n",
        "    test_outputs = best_model(test_input_tensors)\n",
        "    _, test_predicted = torch.max(test_outputs, 1)\n",
        "    test_total += test_label_tensors.size(0)\n",
        "    test_correct += (test_predicted == test_label_tensors).sum().item()\n",
        "\n",
        "test_accuracy = test_correct / test_total\n",
        "print(f'Test Set Accuracy for Best Configuration: {test_accuracy}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgyxFityrZ0m"
      },
      "source": [
        "For p=s=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WA3lRdcVgF3w",
        "outputId": "d87b2c7e-d425-44fa-d87a-cf2e359a17f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dev Set Accuracy for config: {'hidden_size': 256, 'num_layers': 4, 'embedding_dim': 200, 'activation': ReLU()}, Accuracy: 0.9611679711017459\n",
            "Best Hyperparameter Configuration: {'hidden_size': 256, 'num_layers': 4, 'embedding_dim': 200, 'activation': ReLU()}, Dev Set Accuracy: 0.9611679711017459\n",
            "Test Set Accuracy for Best Configuration: 0.9629179331306991\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "from conllu import parse_incr\n",
        "from collections import defaultdict\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "START_TOKEN = '<START>'\n",
        "END_TOKEN = '<END>'\n",
        "\n",
        "\n",
        "train_input_sequences = [create_input_sequence_with_embeddings(sentence, glove_embeddings, CONTEXT_SIZE) for sentence in train_sentences]\n",
        "train_pos_indices = [pos_tag_to_idx[tag] for sentence in train_sentences for _, _, tag in sentence]\n",
        "train_input_sequences_flat = [embedding for sequence in train_input_sequences for embedding in sequence]\n",
        "train_input_tensors = torch.tensor(train_input_sequences_flat, dtype=torch.float32)\n",
        "train_label_tensors = torch.tensor(train_pos_indices, dtype=torch.long)\n",
        "\n",
        "dev_input_sequences = [create_input_sequence_with_embeddings(sentence, glove_embeddings, CONTEXT_SIZE) for sentence in dev_sentences]\n",
        "dev_pos_indices = [pos_tag_to_idx[tag] for sentence in dev_sentences for _, _, tag in sentence]\n",
        "\n",
        "test_input_sequences = [create_input_sequence_with_embeddings(sentence, glove_embeddings, CONTEXT_SIZE) for sentence in test_sentences]\n",
        "test_pos_indices = [pos_tag_to_idx[tag] for sentence in test_sentences for _, _, tag in sentence]\n",
        "\n",
        "dev_input_sequences_flat = [embedding for sequence in dev_input_sequences for embedding in sequence]\n",
        "dev_input_tensors = torch.tensor(dev_input_sequences_flat, dtype=torch.float32)\n",
        "dev_label_tensors = torch.tensor(dev_pos_indices, dtype=torch.long)\n",
        "\n",
        "test_input_sequences_flat = [embedding for sequence in test_input_sequences for embedding in sequence]\n",
        "test_input_tensors = torch.tensor(test_input_sequences_flat, dtype=torch.float32)\n",
        "test_label_tensors = torch.tensor(test_pos_indices, dtype=torch.long)\n",
        "\n",
        "# pos_idx_to_tag = {idx: tag for tag, idx in pos_tag_to_idx.items()}\n",
        "\n",
        "\n",
        "\n",
        "import warnings\n",
        "from conllu import parse_incr\n",
        "from collections import defaultdict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def read_conllu_file(file_path):\n",
        "    sentences = []\n",
        "    pos_tags = set()\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for tokenlist in parse_incr(f):\n",
        "            sentence = []\n",
        "            for token in tokenlist:\n",
        "                word_index = token[\"id\"]\n",
        "                lowercase_word = token[\"form\"].lower()\n",
        "                pos_tag = token[\"upos\"]\n",
        "                sentence.append((word_index, lowercase_word, pos_tag))\n",
        "                pos_tags.add(pos_tag)\n",
        "            sentences.append(sentence)\n",
        "    return sentences, pos_tags\n",
        "\n",
        "def load_glove_embeddings(file_path):\n",
        "    embeddings = {}\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.strip().split(' ')\n",
        "            word = values[0]\n",
        "            vector = np.array(values[1:], dtype=np.float32)\n",
        "            embeddings[word] = vector\n",
        "    return embeddings\n",
        "\n",
        "def create_input_sequence_with_embeddings(sentence, glove_embeddings, context_size):\n",
        "    START_TOKEN = '<START>'\n",
        "    END_TOKEN = '<END>'\n",
        "    sentence_with_tokens = [START_TOKEN] * context_size[0] + [token[1] for token in sentence] + [END_TOKEN] * context_size[1]\n",
        "    input_sequences = []\n",
        "    for i in range(context_size[0], len(sentence_with_tokens) - context_size[1]):\n",
        "        context_words = sentence_with_tokens[i - context_size[0]: i + context_size[1] + 1]\n",
        "        context_embeddings = [glove_embeddings[word] if word in glove_embeddings else np.zeros(EMBEDDING_DIM) for word in context_words]\n",
        "        input_sequence = np.concatenate(context_embeddings)\n",
        "        input_sequences.append(input_sequence)\n",
        "    return input_sequences\n",
        "\n",
        "def predict_pos_tags(sentence, model, glove_embeddings, context_size, pos_idx_to_tag):\n",
        "    START_TOKEN = '<START>'\n",
        "    END_TOKEN = '<END>'\n",
        "    tokens = nltk.word_tokenize(sentence)\n",
        "    sentence_with_tokens = [START_TOKEN] * context_size[0] + [token for token in tokens] + [END_TOKEN] * context_size[1]\n",
        "    input_sequences = []\n",
        "    for i in range(context_size[0], len(sentence_with_tokens) - context_size[1]):\n",
        "        context_words = sentence_with_tokens[i - context_size[0]: i + context_size[1] + 1]\n",
        "        context_embeddings = [glove_embeddings[word] if word in glove_embeddings else np.zeros(EMBEDDING_DIM) for word in context_words]\n",
        "        input_sequence = np.concatenate(context_embeddings)\n",
        "        input_sequences.append(input_sequence)\n",
        "    input_tensor = torch.tensor(input_sequences, dtype=torch.float32)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_tensor)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "    predicted_tags = [pos_idx_to_tag[idx.item()] for idx in predicted]\n",
        "    return predicted_tags\n",
        "\n",
        "train_file = \"en_atis-ud-train.conllu\"\n",
        "dev_file = \"en_atis-ud-dev.conllu\"\n",
        "test_file = \"en_atis-ud-test.conllu\"\n",
        "\n",
        "train_sentences, train_pos_tags = read_conllu_file(train_file)\n",
        "dev_sentences, dev_pos_tags = read_conllu_file(dev_file)\n",
        "test_sentences, test_pos_tags = read_conllu_file(test_file)\n",
        "\n",
        "all_pos_tags = train_pos_tags.union(dev_pos_tags).union(test_pos_tags)\n",
        "pos_tag_to_idx = {tag: idx for idx, tag in enumerate(sorted(all_pos_tags))}\n",
        "pos_idx_to_tag = {idx: tag for tag, idx in pos_tag_to_idx.items()}\n",
        "\n",
        "\n",
        "glove_embeddings = load_glove_embeddings(glove_path)\n",
        "\n",
        "class FFNN_POS_Tagging(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes, num_layers=1, activation=nn.ReLU()):\n",
        "        super(FFNN_POS_Tagging, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.hidden_layers = nn.ModuleList([nn.Linear(hidden_size, hidden_size) for _ in range(num_layers - 1)])\n",
        "        self.relu = activation\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        for layer in self.hidden_layers:\n",
        "            out = layer(out)\n",
        "            out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "hyperparameter_configs = [\n",
        "    {'hidden_size': 256, 'num_layers': 4, 'embedding_dim': 200, 'activation': nn.ReLU()}\n",
        "]\n",
        "\n",
        "train_input_tensors, val_input_tensors, train_label_tensors, val_label_tensors = train_test_split(train_input_tensors, train_label_tensors, test_size=0.1, random_state=42)\n",
        "\n",
        "best_dev_accuracy = 0.0\n",
        "best_config = None\n",
        "\n",
        "CONTEXT_SIZE = (0,0)\n",
        "EMBEDDING_DIM = 100\n",
        "NUM_POS_TAGS = len(pos_tag_to_idx)\n",
        "\n",
        "for config in hyperparameter_configs:\n",
        "    model = FFNN_POS_Tagging(input_size= EMBEDDING_DIM * (sum(CONTEXT_SIZE)+1),\n",
        "                              hidden_size=config['hidden_size'],\n",
        "                              num_classes=NUM_POS_TAGS,\n",
        "                              num_layers=config['num_layers'],\n",
        "                              activation=config['activation'])\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    batch_size = 32\n",
        "    epochs = 10\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        num_batches = len(train_input_tensors) // batch_size\n",
        "        for i in range(num_batches):\n",
        "            batch_inputs = train_input_tensors[i * batch_size: (i + 1) * batch_size]\n",
        "            batch_labels = train_label_tensors[i * batch_size: (i + 1) * batch_size]\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_inputs)\n",
        "            loss = criterion(outputs, batch_labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        avg_loss = running_loss / num_batches\n",
        "\n",
        "    dev_correct = 0\n",
        "    dev_total = 0\n",
        "    with torch.no_grad():\n",
        "        dev_outputs = model(dev_input_tensors)\n",
        "        _, dev_predicted = torch.max(dev_outputs, 1)\n",
        "        dev_total += dev_label_tensors.size(0)\n",
        "        dev_correct += (dev_predicted == dev_label_tensors).sum().item()\n",
        "\n",
        "    dev_accuracy = dev_correct / dev_total\n",
        "    print(f'Dev Set Accuracy for config: {config}, Accuracy: {dev_accuracy}')\n",
        "\n",
        "    if dev_accuracy > best_dev_accuracy:\n",
        "        best_dev_accuracy = dev_accuracy\n",
        "        best_config = config\n",
        "\n",
        "print(f'Best Hyperparameter Configuration: {best_config}, Dev Set Accuracy: {best_dev_accuracy}')\n",
        "\n",
        "\n",
        "best_model = FFNN_POS_Tagging(input_size= EMBEDDING_DIM * (sum(CONTEXT_SIZE)+1),\n",
        "                               hidden_size=best_config['hidden_size'],\n",
        "                               num_classes=NUM_POS_TAGS,\n",
        "                               num_layers=best_config['num_layers'],\n",
        "                               activation=best_config['activation'])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(best_model.parameters(), lr=0.001)\n",
        "\n",
        "final_train_input = torch.cat([train_input_tensors, val_input_tensors], dim=0)\n",
        "final_train_labels = torch.cat([train_label_tensors, val_label_tensors], dim=0)\n",
        "\n",
        "batch_size = 32\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    num_batches = len(final_train_input) // batch_size\n",
        "    for i in range(num_batches):\n",
        "        batch_inputs = final_train_input[i * batch_size: (i + 1) * batch_size]\n",
        "        batch_labels = final_train_labels[i * batch_size: (i + 1) * batch_size]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = best_model(batch_inputs)\n",
        "        loss = criterion(outputs, batch_labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_loss = running_loss / num_batches\n",
        "\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "with torch.no_grad():\n",
        "    test_outputs = best_model(test_input_tensors)\n",
        "    _, test_predicted = torch.max(test_outputs, 1)\n",
        "    test_total += test_label_tensors.size(0)\n",
        "    test_correct += (test_predicted == test_label_tensors).sum().item()\n",
        "\n",
        "test_accuracy = test_correct / test_total\n",
        "print(f'Test Set Accuracy for Best Configuration: {test_accuracy}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pcf8uk25rfHs"
      },
      "source": [
        "for p=s=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwvJEW9lgGbS",
        "outputId": "a23d5351-a708-4d30-e1b9-e395912af30e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dev Set Accuracy for config: {'hidden_size': 256, 'num_layers': 4, 'embedding_dim': 200, 'activation': ReLU()}, Accuracy: 0.9817880794701986\n",
            "Best Hyperparameter Configuration: {'hidden_size': 256, 'num_layers': 4, 'embedding_dim': 200, 'activation': ReLU()}, Dev Set Accuracy: 0.9817880794701986\n",
            "Test Set Accuracy for Best Configuration: 0.9837386018237082\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "from conllu import parse_incr\n",
        "from collections import defaultdict\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "START_TOKEN = '<START>'\n",
        "END_TOKEN = '<END>'\n",
        "\n",
        "\n",
        "train_input_sequences = [create_input_sequence_with_embeddings(sentence, glove_embeddings, CONTEXT_SIZE) for sentence in train_sentences]\n",
        "train_pos_indices = [pos_tag_to_idx[tag] for sentence in train_sentences for _, _, tag in sentence]\n",
        "train_input_sequences_flat = [embedding for sequence in train_input_sequences for embedding in sequence]\n",
        "train_input_tensors = torch.tensor(train_input_sequences_flat, dtype=torch.float32)\n",
        "train_label_tensors = torch.tensor(train_pos_indices, dtype=torch.long)\n",
        "\n",
        "dev_input_sequences = [create_input_sequence_with_embeddings(sentence, glove_embeddings, CONTEXT_SIZE) for sentence in dev_sentences]\n",
        "dev_pos_indices = [pos_tag_to_idx[tag] for sentence in dev_sentences for _, _, tag in sentence]\n",
        "\n",
        "test_input_sequences = [create_input_sequence_with_embeddings(sentence, glove_embeddings, CONTEXT_SIZE) for sentence in test_sentences]\n",
        "test_pos_indices = [pos_tag_to_idx[tag] for sentence in test_sentences for _, _, tag in sentence]\n",
        "\n",
        "dev_input_sequences_flat = [embedding for sequence in dev_input_sequences for embedding in sequence]\n",
        "dev_input_tensors = torch.tensor(dev_input_sequences_flat, dtype=torch.float32)\n",
        "dev_label_tensors = torch.tensor(dev_pos_indices, dtype=torch.long)\n",
        "\n",
        "test_input_sequences_flat = [embedding for sequence in test_input_sequences for embedding in sequence]\n",
        "test_input_tensors = torch.tensor(test_input_sequences_flat, dtype=torch.float32)\n",
        "test_label_tensors = torch.tensor(test_pos_indices, dtype=torch.long)\n",
        "\n",
        "# pos_idx_to_tag = {idx: tag for tag, idx in pos_tag_to_idx.items()}\n",
        "\n",
        "\n",
        "\n",
        "import warnings\n",
        "from conllu import parse_incr\n",
        "from collections import defaultdict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def read_conllu_file(file_path):\n",
        "    sentences = []\n",
        "    pos_tags = set()\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for tokenlist in parse_incr(f):\n",
        "            sentence = []\n",
        "            for token in tokenlist:\n",
        "                word_index = token[\"id\"]\n",
        "                lowercase_word = token[\"form\"].lower()\n",
        "                pos_tag = token[\"upos\"]\n",
        "                sentence.append((word_index, lowercase_word, pos_tag))\n",
        "                pos_tags.add(pos_tag)\n",
        "            sentences.append(sentence)\n",
        "    return sentences, pos_tags\n",
        "\n",
        "def load_glove_embeddings(file_path):\n",
        "    embeddings = {}\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.strip().split(' ')\n",
        "            word = values[0]\n",
        "            vector = np.array(values[1:], dtype=np.float32)\n",
        "            embeddings[word] = vector\n",
        "    return embeddings\n",
        "\n",
        "def create_input_sequence_with_embeddings(sentence, glove_embeddings, context_size):\n",
        "    START_TOKEN = '<START>'\n",
        "    END_TOKEN = '<END>'\n",
        "    sentence_with_tokens = [START_TOKEN] * context_size[0] + [token[1] for token in sentence] + [END_TOKEN] * context_size[1]\n",
        "    input_sequences = []\n",
        "    for i in range(context_size[0], len(sentence_with_tokens) - context_size[1]):\n",
        "        context_words = sentence_with_tokens[i - context_size[0]: i + context_size[1] + 1]\n",
        "        context_embeddings = [glove_embeddings[word] if word in glove_embeddings else np.zeros(EMBEDDING_DIM) for word in context_words]\n",
        "        input_sequence = np.concatenate(context_embeddings)\n",
        "        input_sequences.append(input_sequence)\n",
        "    return input_sequences\n",
        "\n",
        "def predict_pos_tags(sentence, model, glove_embeddings, context_size, pos_idx_to_tag):\n",
        "    START_TOKEN = '<START>'\n",
        "    END_TOKEN = '<END>'\n",
        "    tokens = nltk.word_tokenize(sentence)\n",
        "    sentence_with_tokens = [START_TOKEN] * context_size[0] + [token for token in tokens] + [END_TOKEN] * context_size[1]\n",
        "    input_sequences = []\n",
        "    for i in range(context_size[0], len(sentence_with_tokens) - context_size[1]):\n",
        "        context_words = sentence_with_tokens[i - context_size[0]: i + context_size[1] + 1]\n",
        "        context_embeddings = [glove_embeddings[word] if word in glove_embeddings else np.zeros(EMBEDDING_DIM) for word in context_words]\n",
        "        input_sequence = np.concatenate(context_embeddings)\n",
        "        input_sequences.append(input_sequence)\n",
        "    input_tensor = torch.tensor(input_sequences, dtype=torch.float32)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_tensor)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "    predicted_tags = [pos_idx_to_tag[idx.item()] for idx in predicted]\n",
        "    return predicted_tags\n",
        "\n",
        "train_file = \"en_atis-ud-train.conllu\"\n",
        "dev_file = \"en_atis-ud-dev.conllu\"\n",
        "test_file = \"en_atis-ud-test.conllu\"\n",
        "\n",
        "train_sentences, train_pos_tags = read_conllu_file(train_file)\n",
        "dev_sentences, dev_pos_tags = read_conllu_file(dev_file)\n",
        "test_sentences, test_pos_tags = read_conllu_file(test_file)\n",
        "\n",
        "all_pos_tags = train_pos_tags.union(dev_pos_tags).union(test_pos_tags)\n",
        "pos_tag_to_idx = {tag: idx for idx, tag in enumerate(sorted(all_pos_tags))}\n",
        "pos_idx_to_tag = {idx: tag for tag, idx in pos_tag_to_idx.items()}\n",
        "\n",
        "\n",
        "glove_embeddings = load_glove_embeddings(glove_path)\n",
        "\n",
        "class FFNN_POS_Tagging(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes, num_layers=1, activation=nn.ReLU()):\n",
        "        super(FFNN_POS_Tagging, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.hidden_layers = nn.ModuleList([nn.Linear(hidden_size, hidden_size) for _ in range(num_layers - 1)])\n",
        "        self.relu = activation\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        for layer in self.hidden_layers:\n",
        "            out = layer(out)\n",
        "            out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "hyperparameter_configs = [\n",
        "    {'hidden_size': 256, 'num_layers': 4, 'embedding_dim': 200, 'activation': nn.ReLU()}\n",
        "]\n",
        "\n",
        "train_input_tensors, val_input_tensors, train_label_tensors, val_label_tensors = train_test_split(train_input_tensors, train_label_tensors, test_size=0.1, random_state=42)\n",
        "\n",
        "best_dev_accuracy = 0.0\n",
        "best_config = None\n",
        "\n",
        "CONTEXT_SIZE = (1,1)\n",
        "EMBEDDING_DIM = 100\n",
        "NUM_POS_TAGS = len(pos_tag_to_idx)\n",
        "\n",
        "for config in hyperparameter_configs:\n",
        "    model = FFNN_POS_Tagging(input_size= EMBEDDING_DIM * (sum(CONTEXT_SIZE)+1),\n",
        "                              hidden_size=config['hidden_size'],\n",
        "                              num_classes=NUM_POS_TAGS,\n",
        "                              num_layers=config['num_layers'],\n",
        "                              activation=config['activation'])\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    batch_size = 32\n",
        "    epochs = 10\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        num_batches = len(train_input_tensors) // batch_size\n",
        "        for i in range(num_batches):\n",
        "            batch_inputs = train_input_tensors[i * batch_size: (i + 1) * batch_size]\n",
        "            batch_labels = train_label_tensors[i * batch_size: (i + 1) * batch_size]\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_inputs)\n",
        "            loss = criterion(outputs, batch_labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        avg_loss = running_loss / num_batches\n",
        "\n",
        "    dev_correct = 0\n",
        "    dev_total = 0\n",
        "    with torch.no_grad():\n",
        "        dev_outputs = model(dev_input_tensors)\n",
        "        _, dev_predicted = torch.max(dev_outputs, 1)\n",
        "        dev_total += dev_label_tensors.size(0)\n",
        "        dev_correct += (dev_predicted == dev_label_tensors).sum().item()\n",
        "\n",
        "    dev_accuracy = dev_correct / dev_total\n",
        "    print(f'Dev Set Accuracy for config: {config}, Accuracy: {dev_accuracy}')\n",
        "\n",
        "    if dev_accuracy > best_dev_accuracy:\n",
        "        best_dev_accuracy = dev_accuracy\n",
        "        best_config = config\n",
        "\n",
        "print(f'Best Hyperparameter Configuration: {best_config}, Dev Set Accuracy: {best_dev_accuracy}')\n",
        "\n",
        "\n",
        "best_model = FFNN_POS_Tagging(input_size= EMBEDDING_DIM * (sum(CONTEXT_SIZE)+1),\n",
        "                               hidden_size=best_config['hidden_size'],\n",
        "                               num_classes=NUM_POS_TAGS,\n",
        "                               num_layers=best_config['num_layers'],\n",
        "                               activation=best_config['activation'])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(best_model.parameters(), lr=0.001)\n",
        "\n",
        "final_train_input = torch.cat([train_input_tensors, val_input_tensors], dim=0)\n",
        "final_train_labels = torch.cat([train_label_tensors, val_label_tensors], dim=0)\n",
        "\n",
        "batch_size = 32\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    num_batches = len(final_train_input) // batch_size\n",
        "    for i in range(num_batches):\n",
        "        batch_inputs = final_train_input[i * batch_size: (i + 1) * batch_size]\n",
        "        batch_labels = final_train_labels[i * batch_size: (i + 1) * batch_size]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = best_model(batch_inputs)\n",
        "        loss = criterion(outputs, batch_labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_loss = running_loss / num_batches\n",
        "\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "with torch.no_grad():\n",
        "    test_outputs = best_model(test_input_tensors)\n",
        "    _, test_predicted = torch.max(test_outputs, 1)\n",
        "    test_total += test_label_tensors.size(0)\n",
        "    test_correct += (test_predicted == test_label_tensors).sum().item()\n",
        "\n",
        "test_accuracy = test_correct / test_total\n",
        "print(f'Test Set Accuracy for Best Configuration: {test_accuracy}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8QpvVCarisG"
      },
      "source": [
        "For p=s=3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yH3BDkqLgHRv",
        "outputId": "726ec813-5808-4339-dd57-e75245c9c27e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dev Set Accuracy for config: {'hidden_size': 256, 'num_layers': 4, 'embedding_dim': 200, 'activation': ReLU()}, Accuracy: 0.9754665863937387\n",
            "Best Hyperparameter Configuration: {'hidden_size': 256, 'num_layers': 4, 'embedding_dim': 200, 'activation': ReLU()}, Dev Set Accuracy: 0.9754665863937387\n",
            "Test Set Accuracy for Best Configuration: 0.9803951367781155\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "from conllu import parse_incr\n",
        "from collections import defaultdict\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "START_TOKEN = '<START>'\n",
        "END_TOKEN = '<END>'\n",
        "\n",
        "\n",
        "train_input_sequences = [create_input_sequence_with_embeddings(sentence, glove_embeddings, CONTEXT_SIZE) for sentence in train_sentences]\n",
        "train_pos_indices = [pos_tag_to_idx[tag] for sentence in train_sentences for _, _, tag in sentence]\n",
        "train_input_sequences_flat = [embedding for sequence in train_input_sequences for embedding in sequence]\n",
        "train_input_tensors = torch.tensor(train_input_sequences_flat, dtype=torch.float32)\n",
        "train_label_tensors = torch.tensor(train_pos_indices, dtype=torch.long)\n",
        "\n",
        "dev_input_sequences = [create_input_sequence_with_embeddings(sentence, glove_embeddings, CONTEXT_SIZE) for sentence in dev_sentences]\n",
        "dev_pos_indices = [pos_tag_to_idx[tag] for sentence in dev_sentences for _, _, tag in sentence]\n",
        "\n",
        "test_input_sequences = [create_input_sequence_with_embeddings(sentence, glove_embeddings, CONTEXT_SIZE) for sentence in test_sentences]\n",
        "test_pos_indices = [pos_tag_to_idx[tag] for sentence in test_sentences for _, _, tag in sentence]\n",
        "\n",
        "dev_input_sequences_flat = [embedding for sequence in dev_input_sequences for embedding in sequence]\n",
        "dev_input_tensors = torch.tensor(dev_input_sequences_flat, dtype=torch.float32)\n",
        "dev_label_tensors = torch.tensor(dev_pos_indices, dtype=torch.long)\n",
        "\n",
        "test_input_sequences_flat = [embedding for sequence in test_input_sequences for embedding in sequence]\n",
        "test_input_tensors = torch.tensor(test_input_sequences_flat, dtype=torch.float32)\n",
        "test_label_tensors = torch.tensor(test_pos_indices, dtype=torch.long)\n",
        "\n",
        "# pos_idx_to_tag = {idx: tag for tag, idx in pos_tag_to_idx.items()}\n",
        "\n",
        "\n",
        "\n",
        "import warnings\n",
        "from conllu import parse_incr\n",
        "from collections import defaultdict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def read_conllu_file(file_path):\n",
        "    sentences = []\n",
        "    pos_tags = set()\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for tokenlist in parse_incr(f):\n",
        "            sentence = []\n",
        "            for token in tokenlist:\n",
        "                word_index = token[\"id\"]\n",
        "                lowercase_word = token[\"form\"].lower()\n",
        "                pos_tag = token[\"upos\"]\n",
        "                sentence.append((word_index, lowercase_word, pos_tag))\n",
        "                pos_tags.add(pos_tag)\n",
        "            sentences.append(sentence)\n",
        "    return sentences, pos_tags\n",
        "\n",
        "def load_glove_embeddings(file_path):\n",
        "    embeddings = {}\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.strip().split(' ')\n",
        "            word = values[0]\n",
        "            vector = np.array(values[1:], dtype=np.float32)\n",
        "            embeddings[word] = vector\n",
        "    return embeddings\n",
        "\n",
        "def create_input_sequence_with_embeddings(sentence, glove_embeddings, context_size):\n",
        "    START_TOKEN = '<START>'\n",
        "    END_TOKEN = '<END>'\n",
        "    sentence_with_tokens = [START_TOKEN] * context_size[0] + [token[1] for token in sentence] + [END_TOKEN] * context_size[1]\n",
        "    input_sequences = []\n",
        "    for i in range(context_size[0], len(sentence_with_tokens) - context_size[1]):\n",
        "        context_words = sentence_with_tokens[i - context_size[0]: i + context_size[1] + 1]\n",
        "        context_embeddings = [glove_embeddings[word] if word in glove_embeddings else np.zeros(EMBEDDING_DIM) for word in context_words]\n",
        "        input_sequence = np.concatenate(context_embeddings)\n",
        "        input_sequences.append(input_sequence)\n",
        "    return input_sequences\n",
        "\n",
        "def predict_pos_tags(sentence, model, glove_embeddings, context_size, pos_idx_to_tag):\n",
        "    START_TOKEN = '<START>'\n",
        "    END_TOKEN = '<END>'\n",
        "    tokens = nltk.word_tokenize(sentence)\n",
        "    sentence_with_tokens = [START_TOKEN] * context_size[0] + [token for token in tokens] + [END_TOKEN] * context_size[1]\n",
        "    input_sequences = []\n",
        "    for i in range(context_size[0], len(sentence_with_tokens) - context_size[1]):\n",
        "        context_words = sentence_with_tokens[i - context_size[0]: i + context_size[1] + 1]\n",
        "        context_embeddings = [glove_embeddings[word] if word in glove_embeddings else np.zeros(EMBEDDING_DIM) for word in context_words]\n",
        "        input_sequence = np.concatenate(context_embeddings)\n",
        "        input_sequences.append(input_sequence)\n",
        "    input_tensor = torch.tensor(input_sequences, dtype=torch.float32)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_tensor)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "    predicted_tags = [pos_idx_to_tag[idx.item()] for idx in predicted]\n",
        "    return predicted_tags\n",
        "\n",
        "train_file = \"en_atis-ud-train.conllu\"\n",
        "dev_file = \"en_atis-ud-dev.conllu\"\n",
        "test_file = \"en_atis-ud-test.conllu\"\n",
        "\n",
        "train_sentences, train_pos_tags = read_conllu_file(train_file)\n",
        "dev_sentences, dev_pos_tags = read_conllu_file(dev_file)\n",
        "test_sentences, test_pos_tags = read_conllu_file(test_file)\n",
        "\n",
        "all_pos_tags = train_pos_tags.union(dev_pos_tags).union(test_pos_tags)\n",
        "pos_tag_to_idx = {tag: idx for idx, tag in enumerate(sorted(all_pos_tags))}\n",
        "pos_idx_to_tag = {idx: tag for tag, idx in pos_tag_to_idx.items()}\n",
        "\n",
        "\n",
        "glove_embeddings = load_glove_embeddings(glove_path)\n",
        "\n",
        "class FFNN_POS_Tagging(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes, num_layers=1, activation=nn.ReLU()):\n",
        "        super(FFNN_POS_Tagging, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.hidden_layers = nn.ModuleList([nn.Linear(hidden_size, hidden_size) for _ in range(num_layers - 1)])\n",
        "        self.relu = activation\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        for layer in self.hidden_layers:\n",
        "            out = layer(out)\n",
        "            out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "hyperparameter_configs = [\n",
        "    {'hidden_size': 256, 'num_layers': 4, 'embedding_dim': 200, 'activation': nn.ReLU()}\n",
        "]\n",
        "\n",
        "train_input_tensors, val_input_tensors, train_label_tensors, val_label_tensors = train_test_split(train_input_tensors, train_label_tensors, test_size=0.1, random_state=42)\n",
        "\n",
        "best_dev_accuracy = 0.0\n",
        "best_config = None\n",
        "\n",
        "CONTEXT_SIZE = (3,3)\n",
        "EMBEDDING_DIM = 100\n",
        "NUM_POS_TAGS = len(pos_tag_to_idx)\n",
        "\n",
        "for config in hyperparameter_configs:\n",
        "    model = FFNN_POS_Tagging(input_size= EMBEDDING_DIM * (sum(CONTEXT_SIZE)+1),\n",
        "                              hidden_size=config['hidden_size'],\n",
        "                              num_classes=NUM_POS_TAGS,\n",
        "                              num_layers=config['num_layers'],\n",
        "                              activation=config['activation'])\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    batch_size = 32\n",
        "    epochs = 10\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        num_batches = len(train_input_tensors) // batch_size\n",
        "        for i in range(num_batches):\n",
        "            batch_inputs = train_input_tensors[i * batch_size: (i + 1) * batch_size]\n",
        "            batch_labels = train_label_tensors[i * batch_size: (i + 1) * batch_size]\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_inputs)\n",
        "            loss = criterion(outputs, batch_labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        avg_loss = running_loss / num_batches\n",
        "\n",
        "    dev_correct = 0\n",
        "    dev_total = 0\n",
        "    with torch.no_grad():\n",
        "        dev_outputs = model(dev_input_tensors)\n",
        "        _, dev_predicted = torch.max(dev_outputs, 1)\n",
        "        dev_total += dev_label_tensors.size(0)\n",
        "        dev_correct += (dev_predicted == dev_label_tensors).sum().item()\n",
        "\n",
        "    dev_accuracy = dev_correct / dev_total\n",
        "    print(f'Dev Set Accuracy for config: {config}, Accuracy: {dev_accuracy}')\n",
        "\n",
        "    if dev_accuracy > best_dev_accuracy:\n",
        "        best_dev_accuracy = dev_accuracy\n",
        "        best_config = config\n",
        "\n",
        "print(f'Best Hyperparameter Configuration: {best_config}, Dev Set Accuracy: {best_dev_accuracy}')\n",
        "\n",
        "\n",
        "best_model = FFNN_POS_Tagging(input_size= EMBEDDING_DIM * (sum(CONTEXT_SIZE)+1),\n",
        "                               hidden_size=best_config['hidden_size'],\n",
        "                               num_classes=NUM_POS_TAGS,\n",
        "                               num_layers=best_config['num_layers'],\n",
        "                               activation=best_config['activation'])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(best_model.parameters(), lr=0.001)\n",
        "\n",
        "final_train_input = torch.cat([train_input_tensors, val_input_tensors], dim=0)\n",
        "final_train_labels = torch.cat([train_label_tensors, val_label_tensors], dim=0)\n",
        "\n",
        "batch_size = 32\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    num_batches = len(final_train_input) // batch_size\n",
        "    for i in range(num_batches):\n",
        "        batch_inputs = final_train_input[i * batch_size: (i + 1) * batch_size]\n",
        "        batch_labels = final_train_labels[i * batch_size: (i + 1) * batch_size]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = best_model(batch_inputs)\n",
        "        loss = criterion(outputs, batch_labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_loss = running_loss / num_batches\n",
        "\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "with torch.no_grad():\n",
        "    test_outputs = best_model(test_input_tensors)\n",
        "    _, test_predicted = torch.max(test_outputs, 1)\n",
        "    test_total += test_label_tensors.size(0)\n",
        "    test_correct += (test_predicted == test_label_tensors).sum().item()\n",
        "\n",
        "test_accuracy = test_correct / test_total\n",
        "print(f'Test Set Accuracy for Best Configuration: {test_accuracy}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "ChdbpQnKf-kQ",
        "outputId": "068a91cc-d6eb-4c9b-eb6d-03c84c5834ac"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "accuracies = [96.29, 98.37, 98.27, 98.17, 98.03]\n",
        "indices = list(range(len(accuracies)))\n",
        "\n",
        "plt.plot(indices, accuracies, marker='o')\n",
        "plt.title('Accuracy vs Index')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xticks(indices)\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0YcVH_Y1cj5",
        "outputId": "59cd775b-2808-40f9-f305-c3d58b699d72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dev Set Evaluation:\n",
            "Accuracy: 0.9739614689945816\n",
            "Recall (Micro): 0.9739614689945816\n",
            "Recall (Macro): 0.8893533540178932\n",
            "F1-Score (Micro): 0.9739614689945816\n",
            "F1-Score (Macro): 0.8815304661180864\n",
            "Confusion Matrix:\n",
            "[[ 186    1   23    1    0    4    0   10    0    0    0    2    0    0]\n",
            " [   0 1393    2    0    0    4    0    1    0    7    8    0    0    0]\n",
            " [   2    0   50    1    0    0    0    3    1    0    0    1    0    1]\n",
            " [   0    0    1  254    0    0    0    0    0    0    0    0    0   11]\n",
            " [   0    0    0    0  107    0    0    0    0    0    0    0    0    0]\n",
            " [   0   14    0    0    0  542    0    0    0    0   12    0    0    0]\n",
            " [   0    0    0    0    0    0   35    0    0    0    0    0    0    0]\n",
            " [   0    0    2    0    0    0    0 1128    0    0    0    6    0    7]\n",
            " [   0    0    1    0    0    0    0    1  129    0    0    0    0    0]\n",
            " [   0    1    0    0    1    0    0    0    0   71    0    0    0    0]\n",
            " [   0    0    2    0    0    1    0    0    0    0  411    0    0    0]\n",
            " [   0    0    1    0    0    0    0   13    0    0    0 1536    0    1]\n",
            " [   0    0    0    0    0    0    0    2    0    0    0    0    0    0]\n",
            " [   1   15    3    3    0    0    0    2    0    0    0    0    0  629]]\n",
            "\n",
            "Test Set Evaluation:\n",
            "Accuracy: 0.9791793313069909\n",
            "Recall (Micro): 0.9791793313069909\n",
            "Recall (Macro): 0.9627416749933008\n",
            "F1-Score (Micro): 0.9791793313069909\n",
            "F1-Score (Macro): 0.9585247511284103\n",
            "Confusion Matrix:\n",
            "[[ 199    0   16    0    0    1    1    2    0    0    0    1    0]\n",
            " [   0 1413    2    1    0    6    0    0    0    2   10    0    0]\n",
            " [   5    1   63    0    0    1    0    0    0    0    1    3    2]\n",
            " [   0    0    0  254    0    0    0    0    0    0    0    0    2]\n",
            " [   0    0    1    0  107    0    0    0    0    0    1    0    0]\n",
            " [   0    0    0    0    0  507    0    0    0    0    5    0    0]\n",
            " [   0    0    0    0    0    0   35    1    0    0    0    0    0]\n",
            " [   0    1    2    0    0    0    0 1151    0    0    0    6    6]\n",
            " [   0    0    0    0    0    1    0    1  119    0    0    6    0]\n",
            " [   0    0    0    0    0    0    0    0    0   56    0    0    0]\n",
            " [   0    1    0    0    0    0    0    0    1    0  390    0    0]\n",
            " [   1    0    0    0    0    1    0   12    2    0    0 1550    1]\n",
            " [   0   16    5    3    0    0    1    3    1    0    1    0  599]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Function to evaluate model and generate metrics\n",
        "def evaluate_model(model, input_tensors, label_tensors):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_tensors)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        # Convert tensor predictions and labels to numpy arrays\n",
        "        predicted = predicted.cpu().numpy()\n",
        "        labels = label_tensors.cpu().numpy()\n",
        "\n",
        "        # Compute evaluation metrics\n",
        "        accuracy = accuracy_score(labels, predicted)\n",
        "        recall_micro = recall_score(labels, predicted, average='micro')\n",
        "        recall_macro = recall_score(labels, predicted, average='macro')\n",
        "        f1_micro = f1_score(labels, predicted, average='micro')\n",
        "        f1_macro = f1_score(labels, predicted, average='macro')\n",
        "\n",
        "        # Generate confusion matrix\n",
        "        cm = confusion_matrix(labels, predicted)\n",
        "\n",
        "    return accuracy, recall_micro, recall_macro, f1_micro, f1_macro, cm\n",
        "\n",
        "# Evaluate model on dev set\n",
        "dev_accuracy, dev_recall_micro, dev_recall_macro, dev_f1_micro, dev_f1_macro, dev_cm = evaluate_model(best_model, dev_input_tensors, dev_label_tensors)\n",
        "\n",
        "print(\"Dev Set Evaluation:\")\n",
        "print(f\"Accuracy: {dev_accuracy}\")\n",
        "print(f\"Recall (Micro): {dev_recall_micro}\")\n",
        "print(f\"Recall (Macro): {dev_recall_macro}\")\n",
        "print(f\"F1-Score (Micro): {dev_f1_micro}\")\n",
        "print(f\"F1-Score (Macro): {dev_f1_macro}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(dev_cm)\n",
        "\n",
        "# Evaluate model on test set\n",
        "test_accuracy, test_recall_micro, test_recall_macro, test_f1_micro, test_f1_macro, test_cm = evaluate_model(best_model, test_input_tensors, test_label_tensors)\n",
        "\n",
        "print(\"\\nTest Set Evaluation:\")\n",
        "print(f\"Accuracy: {test_accuracy}\")\n",
        "print(f\"Recall (Micro): {test_recall_micro}\")\n",
        "print(f\"Recall (Macro): {test_recall_macro}\")\n",
        "print(f\"F1-Score (Micro): {test_f1_micro}\")\n",
        "print(f\"F1-Score (Macro): {test_f1_macro}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(test_cm)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
